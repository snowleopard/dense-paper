\documentclass{beamer}
%\includeonlyframes{ew}
\usepackage{graphicx, amssymb}
\usepackage{amsmath}
\usepackage{tikz}
\usepackage{kbordermatrix}

\usetikzlibrary{shapes.arrows,chains,decorations.pathreplacing}
\usetikzlibrary{arrows, decorations.markings, shapes}
\usetikzlibrary{positioning}

\usepackage{theory}



%\usepackage{easybmat}
\usepackage{blkarray}

\newtheorem{hypothesis}{Hypothesis}
%\newcommand{\poly}{\text{poly}}

\setbeamertemplate{footline}[frame number]
\setbeamertemplate{navigation symbols}{}

%\usepackage[T2A]{fontenc}
%\usepackage[cp1251]{inputenc}
%%\usepackage[koi8-r]{inputenc}
%\usepackage[russian]{babel}

\colorlet{dark}{red!85!blue!60!black}
\newcommand{\emp}[1]{{\bf\color{dark}#1}}

\newtheorem{observation}[theorem]{Observation}
%\newtheorem{problem}[theorem]{Open Problem}

\setbeamertemplate{caption}{\raggedright\insertcaption\par}

\def\mpfile#1#2{\includegraphics{#1-#2.mps}}

\author{Vladimir V. Podolskii\inst{1}\\[3mm] \small joint work with Alexander Kulikov, Ivan Mikhailin, Andrey Mokhov}




\institute{
 \inst{1} \  Steklov\ Mathematical\ Institute, Moscow\\
 Higher School of Economics, Moscow\\
}

\date{ISAAC 2019}

\title{Complexity of Linear Operators}

\newcommand{\newfontobj}[2]{
  \newcommand{#1}[1]{
    \expandafter\def\csname##1\endcsname{\ensuremath{#2{##1}}}}}

%\newfontobj{\class}{\mathrm}
%\class{P} \class{FP} \class{UP} \class{FewP}
%\class{NP}\class{coNP} \class{SAT} \class{coNP} \class{PSPACE}
%\class{EXP} \class{QBF} \class{TFNP} \class{TF} \class{F}
%\class{PH} \class{AND} \class{XOR} \class{PARITY} \class{OR}
%\class{MAJ} \class{GT} \class{PARITY}

\newcommand{\PRIMES}{\textsc{PRIMES}}

\newcommand{\bb}[1]{\mathbb{#1}}
%\newcommand{\zo}{\{0,1\}}

\newcommand{\vertex}{\textsc{VertexCover}}
\newcommand{\tropdim}{\textsc{TropDim}}
\newcommand{\tropsolv}{\textsc{TropSolv}}
\newcommand{\tropimpl}{\textsc{TropImpl}}
\newcommand{\tropequiv}{\textsc{TropEquiv}}

\newcommand{\para}[1]{{\color{blue}#1}}

\begin{document}

\tikzstyle{mbrace} = [decorate,decoration={brace,amplitude=5pt}]


\begin{frame}

\titlepage

\end{frame}



\begin{frame}
\frametitle{Setting}

Consider a Boolean matrix $A \in \{0,1\}^{n\times n}$\\
Consider variables $x = (x_1,\ldots, x_n)$ over $\{0,1\}$

\medskip
We want to compute a Boolean linear operator $A x$

\medskip

\[
  A =\begin{bmatrix}
    1 & 0 & 1 & 0 \\
    1 & 1 & 0 & 0 \\
    0 & 1 & 1 & 1 \\
    1 & 1 & 1 & 1 \\
  \end{bmatrix}
 \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ Ax = \left(\begin{array}{@{}l@{}}
    x_1 \vee x_3 \\
    x_1 \vee x_2 \\
    x_2 \vee x_3 \vee x_4 \\
    x_1 \vee x_2 \vee x_3 \vee x_4\\
  \end{array}\right)
  \]



\end{frame}



\begin{frame}
\frametitle{The Model}

\begin{itemize}
\item The computation is a Boolean circuit consisting of $\OR$ gates
\item We start with variables $x_1,\ldots, x_n$
\item In one step we can compute OR of two previously computed expressions
\item Want to compute all the outputs and minimize the number of steps
\end{itemize}

\end{frame}


\begin{frame}
\frametitle{Example}

\[
  A =\begin{bmatrix}
    1 & 0 & 1 & 0 \\
    1 & 1 & 0 & 0 \\
    0 & 1 & 1 & 1 \\
    1 & 1 & 1 & 1 \\
  \end{bmatrix}
 \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \begin{array}{l}
    x_1 \vee x_3 \\
    x_1 \vee x_2 \\
    x_2 \vee x_3 \vee x_4 \\
    x_1 \vee x_2 \vee x_3 \vee x_4\\
  \end{array}
  \]

\medskip
Computation:

$x_1 \vee x_3$ --- output\\
$x_1 \vee x_2$ --- output\\
$x_3 \vee x_4$\\
$x_2 \vee (x_3 \vee x_4)$ --- output\\
$x_1 \vee (x_2 \vee x_3 \vee x_4)$ --- output

\end{frame}


\begin{frame}
\frametitle{Basic facts}

\begin{itemize}%[<+->]
\item One of the simplest Boolean circuit complexity models, studied since 50's
\item Trivial upper bound: $O(n^2)$
\item Counting lower bound: $\Omega(n^2/\log n)$
\item Non-trivial upper bound: $O(n^2/\log n)$ (Lupanov '56)
\item The best explicit lower bound: $\Omega(n^{2 - o(1)})$ (Nechiporuk '70)
\end{itemize}



\end{frame}


\begin{frame}
\frametitle{General setting}

Consider a Boolean matrix $A \in \{0,1\}^{n\times n}$\\
Consider variables $x = (x_1,\ldots, x_n)$ over some semigroup $(S, \circ)$.

\medskip
We want to compute a linear operator $A x$.

\medskip

\[
  A =\begin{bmatrix}
    1 & 0 & 1 & 0 \\
    1 & 1 & 0 & 0 \\
    0 & 1 & 1 & 1 \\
    1 & 1 & 1 & 1 \\
  \end{bmatrix}
 \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ Ax = \left(\begin{array}{@{}l@{}}
    x_1 \circ x_3 \\
    x_1 \circ x_2 \\
    x_2 \circ x_3 \circ x_4 \\
    x_1 \circ x_2 \circ x_3 \circ x_4\\
  \end{array}\right)
  \]

\end{frame}


\begin{frame}
\frametitle{Some semigroups}

\begin{itemize}%[<+->]
\item Boolean semigroup: $(\{0,1\}, \vee)$
\item Integers with addition: $(\mathbb{Z}, +)$
\item $\{0,1\}$ with addition: $(\{0,1\}, \oplus)$
\item Tropical semigroup: $(\mathbb{Z}, \min)$

\end{itemize}


\end{frame}


\begin{frame}
\frametitle{The Problem}

\para{Simplified Problem:} Suppose $A \in \{0,1\}^{n\times n}$ is very dense, that is $A$ has $O(n)$ zeros. How hard is it to compute $Ax$?

\pause
\medskip
Simple observations:
\begin{itemize}[<+->]
\item If instead we consider $A$ containing $O(n)$ ones, the complexity is trivially $O(n)$
\item If $(S,\circ)$ has an inverse operation (is a group), the complexity is trivially $O(n)$
\end{itemize}

\onslide<4>{
\medskip
\para{Problem:} Suppose $A \in \{0,1\}^{n\times n}$ has $z$ zeros. How many operations do we need to compute $Ax$ as a function of $z$?}



\end{frame}


\begin{frame}
\frametitle{Motivation}

\begin{itemize}[<+->]
\item Want to understand the structure of semigroups that are not groups
\item Important examples: Boolean semigroup and tropical semigroup
\item Famous problem of similar flavor: matrix multiplication \\
Given two matrices $A$, $B$, how many operations are needed to compute $A\cdot B$?
\item Non-trivial upper bound over integers: $O(n^{2.373})$ (V.~Williams '12)
\item Known lower bound over tropical semiring: $\Omega(n^3)$ (Kerr '70)
\item Other motivation: connection to range minimum query problem (will see later)
\end{itemize}


\end{frame}


\begin{frame}
\frametitle{Main results}

\begin{theorem}
If $(S,\circ)$ is a commutative semigroup, then $Ax$ can be computed in $O(n)$ operations for dense $A$
\end{theorem}

\pause

\medskip
More generally,
\vspace{-2mm}
\begin{theorem}
If $(S,\circ)$ is a commutative semigroup, and $A$ has $z$ zeros, then $Ax$ can be computed in $O(z)$ operations
\end{theorem}

\pause

\begin{theorem}
If $(S,\circ)$ is strongly non-commutative semigroup, then the maximal complexity of $Ax$ is $\Theta(n\alpha(n))$ operations for dense $A$
\end{theorem}

\medskip
Here $\alpha(n)$ is the inverse Ackermann function

\pause
\medskip
$\alpha(n)$ growth is extremely slow

\medskip
For all practical needs we can assume $\alpha(n)\leq 4$

\end{frame}


\begin{frame}
\frametitle{Connection to RMQ}

\begin{theorem}[simplified upper bound]
For dense $A$ the operator $Ax$ over $(\{0,1\},\vee)$ can be computed is $O(n)$ operations
\end{theorem}


\medskip
First idea: Connection to Range Minimum Query problem (RMQ)

\medskip
This is a standard setting in theory of algorithms

\medskip
We are given an array of numbers $x_1,\ldots, x_n$. We want a data structure to answer queries of the form 
$$
\min\{x_i \mid l\leq i \leq r\}=\ ?
$$ 
for integer $l$ and $r$.

\end{frame}


\begin{frame}
\frametitle{Reduction to RMQ}

Consider
\[
 A =\begin{bmatrix}
    1 & 0 & 1 & 1 & 0 & 1 \\
    1 & 1 & 0 & 1 & 1 & 1 \\
    1 & 0 & 1 & 1 & 1 & 0 \\
    1 & 1 & 1 & 0 & 1 & 1 \\
    0 & 1 & 1 & 1 & 1 & 1 \\
    1 & 0 & 0 & 1 & 1 & 1 \\
    \end{bmatrix}
\]

Split each row into intervals
\[
\begin{array}{lll}
    x_1 & \phantom{0}x_3 \vee x_4 & \phantom{0}x_6 \\
    x_1 \vee x_2& \phantom{0}x_4\vee x_5 \vee x_6 & \\
    x_1& \phantom{0}x_3\vee x_4 \vee x_5 &\\
    x_1\vee x_2 \vee x_3& \phantom{0}x_5 \vee x_6 &\\
    x_2\vee x_3 \vee x_4\vee x_5 \vee x_6 &&\\
    x_1& \phantom{0}x_4 \vee x_5\vee x_6 &\\
    \end{array}
\]

There are $O(n)$ intervals in total, so we reduced our problem to the offline version of RMQ (intervals are given in advance)


\end{frame}


\begin{frame}
\frametitle{Complexity of RMQ}

Unfortunately, best constructions for RMQ give only $O(n \alpha(n))$ complexity in our model, where $\alpha(n)$ is an inverse Ackermann function


\pause
\medskip
Moreover, the following is true
\begin{theorem}[Chazelle, Rozenberg '91]
There are range matrices $A\in \{0,1\}^{n\times n}$ with the complexity $\Omega(n \alpha(n))$
\end{theorem}

So, the reduction to RMQ is not enough for the upper bound


\end{frame}




\begin{frame}
\frametitle{Upper Bound Proof Idea}

\begin{overlayarea}{110mm}{35mm}
\begin{equation*}\only<-1>{A=\left[
\begin{array}{@{}cccccc@{}}
     \ast & \ast  & \ast  & \ast  & \ast  & \ast  \\
     \ast & \ast & \ast  & \ast  & \ast  & \ast  \\
     \ast & \ast & \ast  & \ast  & \ast  & \ast  \\
     \ast & \ast & \ast  & \ast  & \ast  & \ast  \\
     \ast & \ast & \ast  & \ast  & \ast  & \ast  \\
     \ast & \ast & \ast  & \ast  & \ast  & \ast  \\
    \end{array}
    \right]}
\only<2->{
A=\left[
\begin{array}{@{}cccccc@{}}
     \ast & \ast  & \ast  & \ast  & \ast  & \ast  \\
     \ast & \ast & \ast  & \ast  & \ast  & \ast  \\
     \hline
     \ast & \ast & \ast  & \ast  & \ast  & \ast  \\
     \ast & \ast & \ast  & \ast  & \ast  & \ast  \\
     \ast & \ast & \ast  & \ast  & \ast  & \ast  \\
     \ast & \ast & \ast  & \ast  & \ast  & \ast  \\
    \end{array}
    \right]
}
\end{equation*}
\end{overlayarea}

Suppose we have $A$ with $O(n)$ zeros

\pause
\begin{itemize}[<+->]
\item Split rows in two parts: with more than $\log n$ zeros and with at most $\log n$ zeros
\item Computing the second part: intervals are long on average
\item The first part has at most $n/\log n$ rows
\item Computing the first part: switch to the transposed matrix
\end{itemize}


\end{frame}


\begin{frame}
\frametitle{Lower Bound, Proof Scheme}

We prove the following problem equivalences 

\begin{center}
\begin{tikzpicture}[xscale=0.65,line width=1pt]
%\draw[help lines] (0,0) grid (16,6);
\tikzstyle{v}=[rectangle,draw,inner sep=1mm,text width=26mm,above right,minimum height=25mm]

\node[v] (a) at (0,0) {commutative RMQ has $O(s)$ complexity};

\node[v] (b) at (6.5,0) {non-commutative RMQ has $O(s)$ complexity};

\node[v] (c) at (13,0) {non-commutative dense operators $Ax$ have $O(s)$ complexity};

\path (a.10) edge[->] node[above=1cm] {complicated} (b.170);
\path (b.190) edge[->] node[below=1cm] {special case} (a.-10);
\path (b.10) edge[->] node[above=1cm] {straightforward} (c.170);
\path (c.190) edge[->] node[below=1cm] {complicated} (b.-10);
%\node (l1) at (6.5,0) {special case};
\end{tikzpicture}
\end{center}



\end{frame}



\begin{frame}
\frametitle{Open problem}

\begin{problem}[Jukna '19]
Consider $A \in \{0,1\}^{n\times n}$, denote by $\overline{A}$ the bit-wise negation of $A$. How large can
$$
\frac{Complexity(\overline{A}x)}{Complexity(Ax)}
$$ 
be over $(\mathbb{N},+)$ semiring?
\end{problem}

\pause
\medskip
Our result rules out the possibility to achieve large gap with a sparse matrix

\pause
\medskip
\begin{center} \bf Thank you for attention!\end{center}

\end{frame}

\end{document}
